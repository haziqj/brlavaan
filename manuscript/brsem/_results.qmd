### Success rates

```{r}
#| label: tbl-convsucc
#| tbl-cap: 'Success rates for estimation of the two-factor model for the ML, eBR, and iBR methods. Highlighted in red are the scenarios which produced success rates below 50%.'
#| html-table-processing: none

gt(res_conv) |>
  tab_spanner(
    columns = matches("twofac.*0\\.8"),
    label = "Reliability = 0.8",
    id = "twofac80"
  ) |>
  tab_spanner(
    columns = matches("twofac.*0\\.5"),
    label = "Reliability = 0.5",
    id = "twofac50"
  ) |>
  tab_spanner(
    columns = starts_with("twofac"),
    label = "Two-factor model"
  ) |>
  tab_spanner(
    columns = matches("growth.*0\\.8"),
    label = "Reliability = 0.8",
    id = "growth80"
  ) |>
  tab_spanner(
    columns = matches("growth.*0\\.5"),
    label = "Reliability = 0.5",
    id = "growth50"
  ) |>
  tab_spanner(
    columns = starts_with("growth"),
    label = "Growth curve model"
  ) |>
  fmt_percent(contains("0."), decimals = 1) |>
  cols_label(
    contains("ML") ~ "ML",
    contains("eRBM") ~ "eRBM",
    contains("iRBM") ~ "iRBM"
  ) |>
  data_color(
    columns = -all_of("n"),
    domain = c(0, 1.1),
    palette = c("red3", "white",  "white")
  ) |>
  tab_options(table.font.size = "11px")
```


Before evaluating parameter estimates, we first examined the success rate of the estimation methods across all simulation scenarios. 
A successful estimation was determined if 
1) the optimiser reported successful convergence; and 
2) standard errors of estimates fell within acceptable numerical ranges. 
Specifically, for the two-factor model, all standard errors were required to be less than 5, whereas for the growth curve model, reflecting differences in the scaling of observed variables, standard errors needed to be less than 500. 
Additionally, in all cases, we required that the implied covariance matrix $\hat{\Sigma}$ to be positive definite.

In summarising the results we first filtered out the unsuccessful estimation cases.
Our eRBM and iRBM methods demonstrated high success rates overall across simulation conditions, with a few exceptions. 
For sample sizes $n \geq 50$, the success rates were consistently above 85%, reaching 100% convergence for all scenarios with $n=100$ and $n=1000$.

However, we observed notably lower success rates for smaller sample sizes ($n=15,20$), especially pronounced in the two-factor model when employing the eRBM. 
Since convergence criteria were met by the maximum likelihood step, these failures stemmed specifically from numerical instabilities arising during the computation of the derivatives required for the correction term.
Moreover, it is possible that the post-hoc correction brings the parameter estimates outside the feasible parameter space, leading to non-positive definite covariance matrices.
Consequently, caution should be exercised when interpreting eRBM estimates obtained from very small sample scenarios in the two-factor setting.

### Two-factor model results

We first focus on the two-factor model under the scenario with normally distributed errors and high reliability (0.8), as this scenario yielded the highest convergence rates across all estimation methods, enabling a fair and direct comparison.
Similar to the work by @dhaene2022resampling, we focus our evaluation on a subset of key parameters, namely the error variance for item $y_1$, $\Theta_{1,1}$, the second factor loading for item $y_1$, $\Lambda_{2,1}$, the two variance parameters for the latent factors, $\Psi_{1,1}$ and $\Psi_{2,2}$, and the regression coefficient $\beta$.
This selection spans a range of parameter types, providing a comprehensive overview of estimation performance across different components of the model.

The distribution plots of the centred parameter estimates (see @fig-centdist-twofac) revealed substantial variability across all methods at smaller sample sizes.
However, variability decreased notably as the sample size increased. 
@fig-perf-twofac presents the performance metrics for the two-factor model, including relative bias, RMSE, probability of underestimation, and coverage rates.
Across all evaluated conditions, our proposed methods (eRBM and iRBM) consistently achieved reductions in mean bias compared to maximum likelihood (ML), particularly at smaller sample sizes ($n = 15, 20, 50$). 
Root mean square error (RMSE), however, remained approximately equivalent across all methods, indicating similar levels of overall variability, a result visually corroborated by the comparative distribution plots.
Our bias-reduction methods also provided notable improvements in confidence interval coverage, with increases of up to approximately 5% over ML, again primarily in smaller-sample scenarios.

```{r}
#| label: fig-centdist-twofac
#| fig-cap: 'Centered distributions of estimates for the two-factor model (left panel) using normally generated data at 80% reliability. Non-convergence cases and extreme estimates have been excluded. The right panel displays the number of estimates used to compute the summary statistics.'
#| fig-height: 7.5
#| out-width: 100%

p1 <-
  plot_df |>
  filter(param %in% twofacpars) |> 
  ggplot(aes(bias, param, fill = method)) +
  geom_boxplot(alpha = 0.8, outlier.size = 0.3, linewidth = 0.3) +
  # geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = mycols) +
  scale_y_discrete(labels = rev(c(
    expression(Theta["1,1"]),
    expression(Psi["1,1"]),
    expression(Psi["2,2"]),
    expression(beta),
    expression(Lambda["2,1"])
  ))) +
  facet_grid(n ~ .) +
  guides(fill = guide_legend(reverse = TRUE, position = "inside")) +
  theme_bw() +
  theme(
    legend.position.inside = c(0.91, 0.095), 
    legend.background = element_rect(fill = NA), 
    legend.text = element_text(size = 8), 
    legend.title = element_text(size = 9),
    strip.background = element_blank(),
    strip.text = element_blank()    
  ) +
  labs(x = NULL, y = NULL, fill = "Method", subtitle = glue::glue("{plot_df$dist[1]} distribution, reliability = {gsub('Rel = ', '', plot_df$rel[1])}"))

p2 <-
  plot_df |>
  filter(param %in% twofacpars) |> 
  summarise(count = n(), .by = dist:param) |>
  ggplot(aes(count, param, fill = method)) +
  geom_col(width = 0.8, position = position_dodge()) +
  geom_vline(xintercept = 2000, linetype = "dashed") +
  scale_fill_manual(values = mycols) +
  scale_x_continuous(expand = c(0, 0, 0, 100)) +
  facet_grid(n ~ .) +
  theme_bw() +
  theme(
    axis.text.y = element_blank(), 
    axis.ticks.y = element_blank(), 
    axis.text.x = element_text(size = 7.5), 
    legend.position = "none"
  ) +
  labs(x = NULL, y = NULL, subtitle = " ")

cowplot::plot_grid(p1, p2, rel_widths = c(1, 1 / 3))
```


```{r}
#| label: fig-perf-twofac
#| fig-cap: 'Performance metrics (relative bias, RMSE, probability of understimation, and coverage) of the ML, eBR, and iBR methods for estimation of the two-factor model. Vertical dashed lines indicate the ideal values for each metric.'
#| fig-height: 7
#| out-width: 100%
plot_df |> 
  filter(param %in% twofacpars) |> 
  summarise(
    B = mean(bias, na.rm = TRUE, trim = 0.05),
    rmse = sqrt(mean(bias ^ 2, na.rm = TRUE, trim = 0.05)),
    pu = mean(bias < 0),
    covr = mean(covered, na.rm = TRUE),
    .by = c(dist:param)
  ) |>
  pivot_longer(B:covr, names_to = "metric", values_to = "value") |>
  mutate(
    metric = factor(
      metric,
      levels = c("B", "rmse", "pu", "covr"),
      labels = c("Bias", "RMSE", "Prob. underest.", "Coverage")
    )
  ) |>
  ggplot(aes(value, param, fill = method)) +
  geom_col(position = "dodge", width = 0.75) +
  geom_vline(
    data = tibble(
      metric = factor(c("Bias", "RMSE", "Prob. underest.", "Coverage")),
      value = c(0, 0, 0.5, 0.95)
    ),
    aes(xintercept = value),
    linetype = "dashed"
  ) +
  scale_fill_manual(values = mycols) +
  facet_grid(n ~ metric, scales = "free_x") +
  ggh4x::facetted_pos_scales(
    x = list(
      scale_x_continuous(),
      scale_x_continuous(expand = c(0, 0, 0, 0.1)),
      scale_x_continuous(limits = c(0.3, 0.7), labels = scales::percent),
      scale_x_continuous(limits = c(0.6, 1), labels = scales::percent)
    )
  ) +
  scale_y_discrete(labels = rev(c(
    expression(Theta["1,1"]),
    expression(Psi["1,1"]),
    expression(Psi["2,2"]),
    expression(beta),
    expression(Lambda["2,1"])
  ))) +
  guides(fill = guide_legend(reverse = TRUE, position = "bottom")) +
  theme_bw() +
  theme(
    axis.text.x = element_text(size = 7.5),
    legend.key.height = unit(1, "pt"), 
    legend.key.width = unit(9, "pt")
  ) +
  labs(x = NULL, y = NULL, fill = NULL, subtitle = glue::glue("{plot_df$dist[1]} distribution, reliability = {gsub('Rel = ', '', plot_df$rel[1])}"))
```

Comparisons with the resampling-based approaches of @dhaene2022resampling--including the Jackknife, Bootstrap--and the analytic Ozenne method, showed that our methods consistently improved relative mean bias across all reliability settings and distributional scenarios. 
@fig-meanbias-twofac and @fig-rmse-twofac demonstrate the relative mean bias and RMSE of our methods compared to aforementioned methods, respectively.
For brevity, we excluded the Kurtosis scenario from the plots, as it produced roughly similar results to the normal distribution.
The full table of results are available in the Appendix.

While the bias performance of our methods was generally comparable to these established approaches, the resampling-based methods tended to achieve slightly lower bias at the cost of greater variability, particularly pronounced in scenarios with non-normal errors. 
Our eRBM and iRBM methods did not share this disadvantage, providing robust and stable estimates across scenarios.
One notable exception occurred in non-normal conditions with small sample sizes $(n = 15, 20)$, where the eRBM method encountered estimation difficulties, leading to rejection of approximately 60% of parameter estimates. 
This reduced the observed bias performance in these specific cases. 
Despite this, median bias remained close to zero, suggesting that the inflated mean bias was driven predominantly by a small number of extreme estimates attributable to numerical instabilities.


```{r}
#| label: fig-meanbias-twofac
#| fig-cap: 'Comparison of relative mean bias of the ML, eBR, and iBR methods against the D&R methods for estimation of the two-factor model.'
#| out-width: 100%

plot_drcomp |>
  filter(model == "twofac", !method %in% c("lav")) |>
  ggplot(aes(n, relbias, col = method)) +
  geom_line(linewidth = 0.75, alpha = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggh4x::facet_nested(param ~ rel + dist, labeller = label_parsed) +
  scale_color_manual(values = mycols) +
  scale_x_continuous(labels = c(15, 20, 50, 100, 1000)) +
  scale_y_continuous(labels = scales::percent) +
  # coord_cartesian(ylim = c(-0.3, 0.3)) +
  guides(colour = guide_legend(nrow = 1, reverse = TRUE, position = "top")) +
  theme_bw() +
  labs(x = "Sample size (n)", y = glue("Relative mean bias"), col = NULL)
```

```{r}
#| label: fig-rmse-twofac
#| fig-cap: 'Comparison of RMSE of the ML, eBR, and iBR methods against the D&R methods for estimation of the two-factor model.'
#| out-width: 100%

plot_drcomp |>
  filter(model == "twofac", !method %in% c("lav")) |>
  mutate(method = fct_rev(method)) |>
  ggplot(aes(n, rmse, fill = method)) +
  geom_col(position = "dodge", width = 0.75) +
  scale_x_continuous(breaks = 1:5, labels = c(15, 20, 50, 100, 1000)) +
  ggh4x::facet_nested(param ~ rel + dist, labeller = label_parsed) +
  scale_fill_manual(values = mycols) +
  guides(fill = guide_legend(nrow = 1, position = "bottom")) +
  theme_bw() +
  theme(legend.key.height = unit(1, "pt"), legend.key.width = unit(9, "pt")) +
  labs(x = "Sample size (n)", y = "RMSE", fill = NULL)
```

### Growth curve model results

The GCM saw more successful estimation cases than the two-factor SEM, even at smaller sample sizes and low reliability.
We focus on the normal distribution and low reliability (0.5) scenario as this is considered a more challenging case for estimation.
In total there were six free parameters to estimate, but we excluded the intercepts from analyses as these were not particularly interesting. 
The four remaining parameters are all the components in the factor covariance matrix $\Psi$, as well as the equality constrained error variance $\Theta_{1,1}$.

@fig-centdist-growth displays the distribution of estimates for the growth curve model, highlighting the centered distributions of estimates across methods.
Parameter estimates exhibited markedly lower variability--or at least, produced fewer outlier estimates in the boxplots--compared to the two-factor model
This is possibly attributable to the more parsimonious structure of the growth model (6 vs 13 parameters).
@fig-perf-growth presents the performance metrics for the growth curve model, similar to before in the two-factor SEM experiments.
Also consistent with findings from before, both eRBM and iRBM methods yielded substantial improvements in bias and coverage relative to ML, particularly for small to moderate sample sizes. 

RMSE values remained comparable across methods, indicating consistent variability in parameter estimates across different approaches.
Notably, our bias-reduced methods achieved better calibration in terms of median bias. Specifically, our methods consistently resulted in probabilities of underestimating parameters closer to the nominal 50% level, whereas ML tended to systematically overshoot, thus introducing bias.
It was interesting to see that the variance $\Psi_{1,1}$ for the latent factor $\eta_1$ benefited the most from the bias-reduction methods.
For context, the true value of this parameter was set to $\Psi_{1,1}=275$, and the bias was reduced by 30 units (10.9%) at best in the $n=15$ scenario.

```{r}
#| label: fig-centdist-growth
#| fig-cap: 'Centered distributions of estimates for the growth curve model (left panel) using normally generated data at 50% reliability. Non-convergence cases and extreme estimates have been excluded. The right panel displays the number of estimates used to compute the summary statistics.'
#| fig-height: 7.5
#| out-width: 100%

p1 <-
  plot_df50 |>
  filter(param %in% growthpars) |> 
  ggplot(aes(bias, param, fill = method)) +
  geom_boxplot(alpha = 0.8, outlier.size = 0.3, linewidth = 0.3) +
  # geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = mycols) +
  scale_y_discrete(labels = rev(c(
    expression(Theta["1,1"]),
    expression(Psi["1,1"]),
    expression(Psi["2,2"]),
    expression(Psi["1,2"])
  ))) +
  facet_grid(n ~ .) +
  guides(fill = guide_legend(reverse = TRUE, position = "inside")) +
  theme_bw() +
  theme(
    legend.position.inside = c(0.89, 0.095), 
    legend.background = element_rect(fill = NA), 
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 9),
    strip.background = element_blank(),
    strip.text = element_blank()     
  ) +
  labs(x = NULL, y = NULL, fill = "Method", subtitle =  glue::glue("{plot_df50$dist[1]} distribution, reliability = {gsub('Rel = ', '', plot_df50$rel[1])}"))

p2 <-
  plot_df |>
  filter(param %in% growthpars) |> 
  summarise(count = n(), .by = dist:param) |>
  ggplot(aes(count, param, fill = method)) +
  geom_col(width = 0.8, position = position_dodge()) +
  geom_vline(xintercept = 2000, linetype = "dashed") +
  scale_fill_manual(values = mycols) +
  scale_x_continuous(expand = c(0, 0, 0, 100)) +
  facet_grid(n ~ .) +
  theme_bw() +
  theme(
    axis.text.y = element_blank(), 
    axis.ticks.y = element_blank(), 
    axis.text.x = element_text(size = 7.5), 
    legend.position = "none"
  ) +
  labs(x = NULL, y = NULL, subtitle = " ")

cowplot::plot_grid(p1, p2, rel_widths = c(1, 1 / 3))
```


```{r}
#| label: fig-perf-growth
#| fig-cap: 'Performance metrics (relative bias, RMSE, probability of understimation, and coverage) of the ML, eBR, and iBR methods for estimation of the growth curve model. Vertical dashed lines indicate the ideal values for each metric.'
#| fig-height: 7
#| out-width: 100%
plot_df |>
  filter(param %in% growthpars) |> 
  summarise(
    B = mean(bias, na.rm = TRUE, trim = 0.05),
    rmse = sqrt(mean(bias ^ 2, na.rm = TRUE, trim = 0.05)),
    pu = mean(bias < 0),
    covr = mean(covered, na.rm = TRUE),
    .by = c(dist:param)
  ) |>
  pivot_longer(B:covr, names_to = "metric", values_to = "value") |>
  mutate(
    metric = factor(
      metric,
      levels = c("B", "rmse", "pu", "covr"),
      labels = c("Bias", "RMSE", "Prob. underest.", "Coverage")
    )
  ) |>
  ggplot(aes(value, param, fill = method)) +
  geom_col(position = "dodge", width = 0.75) +
  geom_vline(
    data = tibble(
      metric = factor(c("Bias", "RMSE", "Prob. underest.", "Coverage")),
      value = c(0, 0, 0.5, 0.95)
    ),
    aes(xintercept = value),
    linetype = "dashed"
  ) +
  scale_fill_manual(values = mycols) +
  facet_grid(n ~ metric, scales = "free_x") +
  ggh4x::facetted_pos_scales(
    x = list(
      scale_x_continuous(),
      scale_x_continuous(expand = c(0, 0, 0, 10)),
      scale_x_continuous(limits = c(0.35, 0.65), labels = scales::percent),
      scale_x_continuous(limits = c(0.6, 1), labels = scales::percent)
    )
  ) +
  scale_y_discrete(labels = rev(c(
    expression(Theta["1,1"]),
    expression(Psi["1,1"]),
    expression(Psi["2,2"]),
    expression(Psi["1,2"])
  ))) +
  guides(fill = guide_legend(reverse = TRUE, position = "bottom")) +
  theme_bw() +
  theme(
    axis.text.x = element_text(size = 7.5),
    legend.key.height = unit(1, "pt"), 
    legend.key.width = unit(9, "pt")
  ) +  
  labs(x = NULL, y = NULL, fill = NULL, subtitle = glue::glue("{plot_df$dist[1]} distribution, reliability = {gsub('Rel = ', '', plot_df$rel[1])}"))
```

Next, we compared our methods to the competitor methods, including REML.
It is noted that the constraint of equal error variances across all 10 items contributed to the stabilisation of estimates, promoting bias reduction via averages.
This is seen clearly in the previous figures, as well as when comparing across methods (see @fig-meanbias-growth).
In the scenario involving normally distributed data, REML generally provided the lowest relative mean bias among all methods.
This result was expected given REMLâ€™s theoretical optimality in estimating variance components under normality. 
On the flip side, REML exhibited substantially poorer performance under non-normal data conditions, underscoring its lack of robustness against departures from normality.

The results are, on the whole, expected.
The bias performance of our proposed eRBM and iRBM methods was consistently comparable--and occasionally superior--to existing resampling-based methods (Jackknife, Bootstrap) and the analytic Ozenne approach. 
Unlike REML, our methods maintained robustness in non-normal settings without compromising performance.

In low reliability scenarios, the estimate of the latent slope-intercept covariance $\Psi_{1,2}$ tended to be the most unstable in small samples. 
Our methods did a great job in reducing the bias of this parameter, considering both ML and REML gave much greater bias.
Notably, for $n\geq 100$, differences between methods converge, with all methods yielding similar performance.
This emphasises that bias reduction is most valueable in small to moderate sample regimes, where ML is particularly vulnerable.

```{r}
#| label: fig-meanbias-growth
#| fig-cap: 'Comparison of relative mean bias of the ML, eBR, and iBR methods against the D&R methods for estimation of the growth curve model.'
#| out-width: 100%

plot_drcomp |>
  filter(model == "growth", !method %in% c("lav")) |>
  ggplot(aes(n, relbias, col = method)) +
  geom_line(linewidth = 0.75, alpha = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggh4x::facet_nested(param ~ rel + dist, labeller = label_parsed) +
  scale_color_manual(values = mycols) +
  scale_x_continuous(labels = c(15, 20, 50, 100, 1000)) +
  scale_y_continuous(labels = scales::percent) +
  # coord_cartesian(ylim = c(-0.25, 0.25)) +
  guides(colour = guide_legend(nrow = 1, reverse = TRUE, position = "top")) +
  theme_bw() +
  labs(x = "Sample size (n)", y = "Relative mean bias", col = NULL)
```

```{r}
#| label: fig-rmse-growth
#| fig-cap: 'Comparison of RMSE of the ML, eBR, and iBR methods against the D&R methods for estimation of the growth curve model.'
#| out-width: 100%

plot_drcomp |>
  filter(model == "growth", !method %in% c("lav")) |>
  mutate(method = fct_rev(method)) |>
  ggplot(aes(n, rmse, fill = method)) +
  geom_col(position = "dodge", width = 0.75) +
  scale_x_continuous(breaks = 1:5, labels = c(15, 20, 50, 100, 1000)) +
  ggh4x::facet_nested(param ~ rel + dist, labeller = label_parsed) +
  scale_fill_manual(values = mycols) +
  # coord_cartesian(ylim = c(0, 280)) +
  guides(fill = guide_legend(nrow = 1, position = "bottom")) +
  theme_bw() +
  theme(legend.key.height = unit(1, "pt"), legend.key.width = unit(9, "pt")) +
  labs(x = "Sample size (n)", y = "RMSE", fill = NULL)
```
