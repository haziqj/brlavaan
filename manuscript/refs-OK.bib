@article{jeffreys1946prior,
  author = {Jeffreys, Harold},
  title = {An invariant form for the prior probability in estimation problems},
  journal = {Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences},
  volume = {186},
  number = {1007},
  pages = {453-461},
  year = {1946},
  doi = {10.1098/rspa.1946.0056},
  abstract = {It is shown that a certain differential form depending on the values of the parameters in a law of chance is invariant for all transformations of the parameters when the law is differentiable with regard to all parameters. For laws containing a location and a scale parameter a form with a somewhat restricted type of invariance is found even when the law is not everywhere differentiable with regard to the parameters. This form has the properties required to give a general rule for stating the prior probability in a large class of estimation problems. }
}


@book{efron1994bootstrap,
  title={An Introduction to the Bootstrap},
  author={Efron, B. and Tibshirani, R.J.},
  isbn={9780412042317},
  lccn={93004489},
  series={Chapman \& Hall Ltd.},
  doi={https://doi.org/10.1201/9780429246593},
  year={1994},
  publisher={Taylor \& Francis}
}

@article{hall1988bootstrap,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2336307},
 abstract = {We propose a single unifying approach to bootstrap resampling, applicable to a very wide range of statistical problems. It enables attention to be focused sharply on one or more characteristics which are of major importance in any particular problem, such as coverage error or length for confidence intervals, or bias for point estimation. Our approach leads easily and directly to a very general form of bootstrap iteration, unifying and generalizing present disparate accounts of this subject. It also provides simple solutions to relatively complex problems, such as a suggestion by Lehmann (1986) for `conditionally' short confidence intervals.},
 author = {Peter Hall and Michael A. Martin},
 journal = {Biometrika},
 number = {4},
 pages = {661--671},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {On Bootstrap Resampling and Iteration},
 urldate = {2022-05-13},
 volume = {75},
 year = {1988}
}


@article{quenouille1956jackknife,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2332914},
 author = {M. H. Quenouille},
 journal = {Biometrika},
 number = {3/4},
 pages = {353--360},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Notes on Bias in Estimation},
 urldate = {2022-05-12},
 volume = {43},
 year = {1956}
}


@book{efron1982jackknife,
author = {Efron, Bradley},
title = {The Jackknife, the Bootstrap and Other Resampling Plans},
publisher = {Society for Industrial and Applied Mathematics},
year = {1982},
doi = {10.1137/1.9781611970319}
}

@article{gourieroux1993indirect,
 ISSN = {08837252, 10991255},
 URL = {http://www.jstor.org/stable/2285076},
 abstract = {In this paper we present inference methods which are based on an `incorrect' criterion, in the sense that the optimization of this criterion does not directly provide a consistent estimator of the parameter of interest. Moreover, the argument of the criterion, called the auxiliary parameter, may have a larger dimension than that of the parameter of interest. A second step, based on simulations, provides a consistent and asymptotically normal estimator of the parameter of interest. Various testing procedures are also proposed. The methods described in this paper only require that the model can be simulated, therefore they should be useful for models whose complexity rules out a direct approach. Various fields of applications are suggested (microeconometrics, finance, macroeconometrics).},
 author = {C. Gourieroux and A. Monfort and E. Renault},
 journal = {Journal of Applied Econometrics},
 number = {},
 pages = {S85--S118},
 publisher = {Wiley},
 title = {Indirect Inference},
 urldate = {2022-05-14},
 volume = {8},
 year = {1993}
}


@article{kosmidis2014bias,
    author = {Kosmidis, Ioannis},
    title = {Bias in parametric estimation: reduction and useful side-effects},
    journal = {WIREs Computational Statistics},
    volume = {6},
    number = {3},
    pages = {185-196},
    keywords = {jackknife/bootstrap, indirect inference, penalized likelihood, infinite estimates, separation in models with categorical responses},
    doi = {https://doi.org/10.1002/wics.1296},
    url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.1296},
    eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1296},
    abstract = {The bias of an estimator is defined as the difference of its expected value from the parameter to be estimated, where the expectation is with respect to the model. Loosely speaking, small bias reflects the desire that if an experiment is repeated indefinitely then the average of all the resultant estimates will be close to the parameter value that is estimated. The current article is a review of the still-expanding repository of methods that have been developed to reduce bias in the estimation of parametric models. The review provides a unifying framework where all those methods are seen as attempts to approximate the solution of a simple estimating equation. Of particular focus is the maximum likelihood estimator, which despite being asymptotically unbiased under the usual regularity conditions, has finite-sample bias that can result in significant loss of performance of standard inferential procedures. An informal comparison of the methods is made revealing some useful practical side-effects in the estimation of popular models in practice including: (1) shrinkage of the estimators in binomial and multinomial regression models that guarantees finiteness even in cases of data separation where the maximum likelihood estimator is infinite and (2) inferential benefits for models that require the estimation of dispersion or precision parameters. This article is categorized under: Data: Types and Structure > Categorical Data Algorithms and Computational Methods > Maximum Likelihood Methods Statistical and Graphical Methods of Data Analysis > Bootstrap and Resampling},
    year = {2014}
}


@book{cox1974theoretical,
  title={Theoretical statistics},
  author={Cox, David Roxbee and Hinkley, David Victor},
  year={1974},
  publisher={Chapman and Hall/CRC},
  edition={First},
  doi={https://doi.org/10.1201/b14832}
}


@Manual{gilbert2022numderiv,
    title = {numDeriv: Accurate Numerical Derivatives},
    author = {Paul Gilbert and Ravi Varadhan},
    year = {2022},
    note = {R package version 2022.9-1/r1909},
    url = {https://R-Forge.R-project.org/projects/optimizer/},
  }
