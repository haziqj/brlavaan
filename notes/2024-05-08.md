---
title: "Bias reduction for SEM"
format: html
embed-resources: true
---

[![hackmd-github-sync-badge](https://hackmd.io/FnIx6HCnR3a3eGJt1alNlw/badge)](https://hackmd.io/FnIx6HCnR3a3eGJt1alNlw)

## Introduction

(Summary of Dhaene & Rosseel, 2022) The motivation for doing bias correction in structural equation models (SEMs) stems from the issue that estimates obtained via Maximum Likelihood (ML), which is the typical estimation method for SEMs, are prone to finite sample bias. This bias occurs because ML estimation is grounded in large sample theory, and its accuracy can be compromised when applied to small samples. Bias correction is therefore important to improve the accuracy and validity of the parameter estimates in SEMs, especially when the sample size is not large enough to satisfy the assumptions of large sample theory.

Situations where one would want to do bias correction include:
- When working with small sample sizes that do not meet the assumptions of large sample theory, leading to biased estimates.
- When the SEM is not mathematically equivalent to mixed effect models, which means that methods like Restricted Maximum Likelihood (REML) that can alleviate bias are not applicable.
- In cases where non-normal data or low reliability might exacerbate the bias in parameter estimates.

Resampling based corrections, such as Bootstrap and Jackknife methods, are viable alternatives for bias correction in SEMs, particularly when dealing with small sample sizes or when REML is not applicable.

The limitations of the resampling method for bias correction of SEM include:

- An increase in variability: While resampling methods such as Bootstrap and Jackknife can effectively reduce bias, they also tend to increase the variability of the estimates.
- Non-normal data: The effectiveness of resampling methods may be compromised when dealing with non-normal data, which is a common issue in real-world data sets.
- Low reliability: Situations with low reliability in the data can also affect the performance of resampling methods, potentially leading to less accurate bias correction.
- Increase computation time.

## Proposal

Explore suitability of empirical bias reduction methods to SEM.

## Simulations

What scenarios to run?

1. Growth curve model
2. Two factor SEM
3. Others?

Competitors:
1. MLE (no bias correction)
2. Jackknife
3. Bootstrap
4. REML ???
5. Ozenne et al ???
6. *explicit brm*
7. *implicit brm*

### Framework

- Create `rb_xxxx()` functions that take arguments `object` (`{lavaan}` fit or otherwise) and maybe `data`. It should spit out:
    1. Bias reduced coefficients
    2. Whether or not the methods successfully "converged"^[Need to define what it means for a method to converge for each of the competitors]
    3. If not converged, what is it that is returned?
    4. Standard errors for confidence intervals ???
    5. Timing

- Simulation routine goes like this
    - for (i in no_sims) do
        - for (m in scenarios) do
            - Simulate data according to model/scenario m
            - Fit the model and obtain the required things for each of the competitors
            - Tabulate the output
        - end for
    - end for

- Analyse the output (tables/graphs)

## TODO

- [ ] Decide on "competitors".
- [ ] Do we need the standard errors for confidence intervals?
- [ ] Decide on scenarios to run.
- [ ] How to do the implicit brm?
    - [ ] How to get the H and J matrices efficiently? Any closed form solutions?
